---
title: "R Notebook"
output: html_notebook
---

Chapter 4 examples  

```{r}
library(tidyverse)
library(rethinking)

```


Multiplicative can produce normal distribution.  
```{r}
prod(1+ runif(12,0,0.1))
plot(density(purrr::map_dbl(1:100, ~ prod(1+runif(12,0,0.01)))))
```



Prior predictive distribution  

```{r}
## mu ~ N(178,20)
## sigma ~ U(0,50)

## test out different values of sigma and mu  

sample_mu <- rnorm(1e5,178,20)  
sample_sigma <- runif(1e5,0,5)
sample_h <- rnorm(1e5,sample_mu,sample_sigma)
rethinking::dens(sample_h)

```





**Grid approximation**    
```{r}
data(Howell1)
d <- Howell1

d2 <- d %>%
  filter(age>=18)

mu_list <- seq(140,160,length.out = 200)
sigma_list <- seq(4,9,length.out = 200)
post <- crossing(mu_list,sigma_list)


ll_fun <- function(heights,x) {
  sum(dnorm(
    heights,
    #mean = post$mu_list[x],
    #sd = post$sigma_list[x],
    mean = as_vector(post[x,"mu_list"]),
    sd =   as_vector(post[x,"sigma_list"]),
    log = TRUE
  ))
}

## log likelhood  
## log of posterior will be ll + prior(mu) + prior(sigma)  
post <- post %>%
  mutate(ll = map_dbl(1:nrow(post), ~ ll_fun(d2$height, .x)),
         prod = ll + dnorm(mu_list,178,20, log = TRUE) + dunif(sigma_list,0,50,log = TRUE),
         prob = exp(prod - max(prod)))
```

`post` now describes the posterior distribution of `mu` and `sigma`.  

Samplgin

Visualize the grid  
```{r}
post %>%
  dplyr::sample_n(.,1e4,weight = prob, replace = TRUE) %>%
  ggplot(aes(mu_list,sigma_list)) + geom_jitter(aes(color = prob)) + scale_color_gradient2(midpoint = 0.5)

```


**Quadratice approximation**   
We will repeat the above using maximum a posteriori estimate (map)
```{r}
flist <- alist(
  height ~ dnorm(mu, sigma),
  mu ~ dnorm(178,20),
  sigma ~ dunif(0,50)
)

## fit the model  

m4_1 <- map(flist,data = d2)

```

Inspect it 
```{r}
precis(m4_1)

## sampling posterior  
post <- extract.samples(m4_1,n = 1e4)
head(post)
 
```

#### Adding a predictor  

```{r}
d2 %>%
  ggplot(.,aes(height,weight)) + geom_jitter()
```


Modeling height and weight    

```{r}
flist <- alist(
  height ~dnorm(mu,sigma),
  mu <- a + b*weight,
  a ~ dnorm(178,100),
  b ~ dnorm(0,10),
  sigma <- dunif(0,50)
)

m4_3 <- map(flist,data = d2)

```


We can extract samples from this posterior distribution  
```{r}
post <- extract.samples(m4_3)
post %>%
  head


post %>%
  ggplot(aes(a,b)) + geom_line()

```

What if we'd like to visualzie the uncertainity?  The `link` function in the `rethinking` package, lets us draw a posterior distribution of `mu`, for any weight value we provide.   

```{r}
mu <- link(m4_3)

str(mu)

```

Each column is an individual and the rows are the posteriro distribution for that partiuclar weight.  

We can define a sequnece of weights and get a posterior distribution for those weights.  

```{r}
weight_seq <- seq(25,70,1)
mu <- link(m4_3, data = data.frame(weight = weight_seq))
str(mu)

plot(height ~ weight, d2, type = "n")
walk(1:1000, ~points(weight_seq,mu[.x,],pch = 16,col = col.alpha(rangi2,0.1)))

```

*Prediction intervals*  

To generate prediction intervals, here's what we need to do  
1.  For a given weight, sample from the posterior distribution with the `mu` and `sigma`. The `mu` is calculated by a + b*weight   
The `post` df should have everything we need  

```{r}
post <- extract.samples(m4_3)
head(post)

## Function that samples from the posterior distribution  
sim_fn <- function(weight) {
  rnorm(nrow(post), mean = post$a + post$b*weight,sd = post$sigma)
}

## Create simulate heights for all sequence of weights  
sim_list <- purrr::map(weight_seq, ~ sim_fn(.x)) %>% do.call(cbind,.) %>% as.data.frame()
height_pi <- purrr::map(sim_list, ~ PI(.x))

```



**Splines**   
```{r}
library(splines)
data("cherry_blossoms")
d <- cherry_blossoms
glimpse(d)


d %>%
  filter(is.na(temp))

## 91 NAs in temp - 
## we need complete data   

d2 <- d %>%
  filter(!is.na(temp))
glimpse(d2)

```

Exploring  
```{r}
d2 %>%
  ggplot(.,aes(year,temp)) + geom_line()
```

B-Splines  

We decide to use 15 knots to model the year and tempretarure relationship  

```{r}
knots <- 15 
knots_loc <- quantile(d2$year,probs = seq(0,1,length.out = knots))

## create the b-spline matrix   
B <- bs(d2$year , knots = knots_loc[-c(1,knots)], degree = 3,intercept = TRUE)

```

How do we now model this?  Each B spline will have it's own parameter (or weight), and this will need to be another paratmer estimated from the data (and will have it's own prior).   



```{r}
flist <- alist(
  temp ~ dnorm(mu, sigma),
  mu <- a + B%*%w,
  a ~ dnorm(6,10),
  w ~ dnorm(0,1),
  sigma ~ dexp(1)
)

m4_7 <- quap(flist, data=list(temp = d2$temp, B = B), start =list(w = rep(0 , ncol(B))))

```

Inspect the model  and plot the posterior predcitions   

```{r}
post <- extract.samples(m4_7)
mu <- link(m4_7)
mu <- mu %>% as_tibble(,.name_repair = "unique")

## Use the PI function in the rethinkging paca
pi_mu <- purrr::map_df(mu, ~PI(.x,0.97))

## transpose the df 
pi_mu <- pi_mu %>%
  mutate(interval = c("lower","upper")) %>%
  gather(key = "v",value = "value",-interval) %>%
  select(-v) %>%
  mutate(dummy_col = seq(1,nrow(.),by = 1)) %>%
  spread(key = interval,value = value) %>%
  fill(.,lower) %>%
  fill(.,upper, .direction = "up") %>%
  distinct(., lower, .keep_all = TRUE)

## Plot the 97% PI for mu  

d2 %>%
  bind_cols(.,pi_mu) %>%
  ggplot(.,aes(year,temp)) + geom_point()  + geom_ribbon(aes(ymin = lower, ymax = upper))

```






#### Homework  
Practice some homework problems  


Plot the prior predictive distribution for thepolynomial regressionmodel in Chapter 4. You can modify the the code that plots the linear regression prior predictive distribution. 20 or 30 parabolas from the prior should suffice to show where the prior probability resides. Can you modify the  prior distributions of α, β1, and β2 so that the prior predictions stay within the biologically reasonable outcomespace? That is tosay: Do not try to fit the data by hand. But do try to keep the curves consistent with what you know about height and weight,before seeing these exact data.


```{r}
data("Howell1")
d <- Howell1
glimpse(d)

```

First recreate the linear model from the book   

```{r}
## standardize the predictors  
d <- d %>%
  mutate(weight = scale(weight, center = TRUE,scale = FALSE))

flist <- alist(
  height ~ dnorm(mu,sigma),
  mu <- a + b1*weight,
  a ~ dnorm(178,20),
  b1 ~ dgamma(2),
  sigma ~ dexp(1)
)
fit <- quap(flist,data = d)

## Now we only want to sample the prior  

prior <- extract.prior(fit)   
prior <- prior %>%
  bind_cols()


## Assign the original data again (we need uncentered weight)   
d <- Howell1

prior_sim <- function(x) {
out <- prior$a[x] + prior$b1[x]*((seq(20,60,by = 0.1) - mean(d$weight)))
return(out)
}

height_simulations <- purrr::map(1:40, ~ prior_sim(.x))
names(height_simulations) <- seq(1,40,by = 1)


height_simulations %>%
  bind_cols() %>%
  gather() %>%
  mutate(weight = rep(seq(20,60,by = 0.1), times = 40)) %>%
  ggplot(.,aes(weight, value, group = key)) + geom_line()

```


Played around with several priors, the results match the book so it means this method works well to simulate from the prior.  **Maybe write a blog plost** ?  







Fit a polynomial model with a quadratic term. The priors we choose for the beta terms are pretty diffuse  

a ~ normal(178,20) (the intercept)
b1 ~ normal(0,10) (slope for the linear term)
b2 ~ normal(0,10) (slope for the quadratic term)  



```{r}

## standardize the predictors  
d <- d %>%
  mutate(weight_2 = weight^2) %>%
  mutate(weight = scale(weight, center = TRUE,scale = FALSE), weight_2 = scale(weight_2,center = TRUE, scale = FALSE))

flist <- alist(
  height ~ dnorm(mu,sigma),
  mu <- a + b1*weight + b2*weight_2,
  a ~ dnorm(178,20),
  b1 ~ dnorm(0,10),
  b2 ~ dnorm(0,10),
  sigma ~ dexp(1)
)
fit <- quap(flist,data = d, start = list(a = 170,b1 = 1, b2 = 1))


## Now we only want to sample the prior  

prior <- extract.prior(fit)   
prior <- prior %>%
  bind_cols()


## unstandardize data  
d <- Howell1

prior_sim <- function(x) {
out <- prior$a[x] + prior$b1[x]*((seq(20,60,by = 0.1) - mean(d$weight))/sd(d$weight)) + 
  prior$b1[x]*((seq(20,60,by = 0.1) - mean(d$weight))/sd(d$weight))^2
return(out)
}

height_simulations <- purrr::map(1:40, ~ prior_sim(.x))
names(height_simulations) <- seq(1,40,by = 1)

height_simulations %>%
  bind_cols() %>%
  gather() %>%
  mutate(weight = rep(seq(20,60,by = 0.1), times = 40)) %>%
  ggplot(.,aes(weight, value, group = key)) + geom_line()


```

We see negative slopes and height decreasing with age - although that may happen but it happends on a millimetre scale.  Clearly we can and should do better.   

One way is by forcing the slopes to be positive.  We can use the lognormal distribution.  The book tries the log normal for the linear, try the halfnormal??  

```{r}
d <- Howell1
## standardize the predictors  
d <- d %>%
  mutate(weight = scale(weight, center = TRUE,scale = TRUE)) %>%
  mutate(weight_2 = weight^2)
  
flist <- alist(
  height ~ dnorm(mu,sigma),
  mu <- a + b1*weight + b2*weight_2,
  a ~ dnorm(178,20),
  b1 ~ dlnorm(2,1),
  b2 ~ dnorm(1,10),
  sigma ~ dunif(0,50)
)
fit <- quap(flist,data = d)


## Now we only want to sample the prior  

prior <- extract.prior(fit)   
prior <- prior %>%
  bind_cols()


## unstandardize data  
#d <- Howell1



prior_sim <- function(x) {
out <- prior$a[x] + prior$b1[x]*(d$weight) + 
  prior$b2[x]*d$weight_2
return(out)
}


height_simulations <- purrr::map(1:100, ~ prior_sim(.x))
names(height_simulations) <- seq(1,100,by = 1)

height_simulations %>%
  bind_cols() %>%
  gather() %>%
  mutate(weight = rep(d$weight, times = 100)) %>%
  ggplot(.,aes(weight, value, group = key)) + geom_line() +scale_y_continuous(limits = c(50,275))

```





Tried different priors.  Got a good understanding of how to simulate priors.  `rethinking` package has a function `link` that does it all together but good to do it yourself and understand better.   





Visualizing different distributions  

```{r}


  purrr::map2(seq(1,10,by = 1),seq(1,10,1), ~ rgamma(1000,.x,.y)) %>%
  as_tibble(.,.name_repair = "unique") %>%
  gather() %>%
  ggplot(aes(value, color = key)) + geom_density() + theme_void() + theme(plot.b=element_rect("black"),legend.p="none")



purrr::map2(seq(1,100,by = 1),seq(1,100,1), ~ rweibull(1000,.x,.y)) %>%
  as_tibble(.,.name_repair = "unique") %>%
  gather() %>%
  ggplot(aes(value, color = key)) + geom_density() + theme_void() + theme(plot.b=element_rect("black"),legend.p="none")



purrr::map(seq(1,10,by = 1), ~ rweibull(1000,.x,.01)) %>%
  as_tibble(.,.name_repair = "unique") %>%
  gather() %>%
  ggplot(aes(value, color = key)) + geom_density() + theme_void() + theme(plot.b=element_rect("black"),legend.p="none")

```




